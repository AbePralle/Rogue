class Preprocessor
  GLOBAL PROPERTIES
    definitions = Table<<String,Token[]>>()

  GLOBAL METHODS
    method define( name:String, definition:String )
      define( name, Tokenizer().tokenize("[Command Line]",definition) )

    method define( name:String, tokens:Token[] )
      definitions[ name ] = tokens

  PROPERTIES
    parser : Parser  # the parser that will be parsing these tokens later
    reader : PreprocessorTokenReader
    tokens : Token[]

    cur_module : String

  METHODS
    method init( parser )

    method process( tokens )->Token[]
      reader = PreprocessorTokenReader( tokens )
      tokens = Token[]( (tokens.count * 1.1)->Int32 )
      process( true, 0, false )

      return tokens

    # -------------------------------------------------------------------------

    method consume( type:TokenType )->Logical
      if (reader.peek.type is not type) return false
      reader.read
      return true

    method consume( identifier:String )->Logical
      local t = reader.peek
      if (t.type is not TokenType.identifier) return false
      if (t->String != identifier) return false
      reader.read
      return true

    method process( keep_tokens:Logical, depth:Int32, stop_on_eol:Logical )
      ++depth
      local repeat_string_concatenation = false
      while (reader.has_another)
        local t = reader.read

        if (t.is_directive)
          if (t.type is TokenType.directive_compileArg)
            if (keep_tokens)
              local def_t = reader.read
              if (def_t.type is not TokenType.literal_string)
                throw reader.error( "Literal string expected (e.g. \"-pthread\"." )
              endIf
              RogueC.compiler_options.add( def_t->String )
            endIf
            nextIteration

          elseIf (t.type is TokenType.directive_define)
            if (keep_tokens)
              local defined_word = reader.read_identifier
              local defined_tokens = Token[]()
              while (reader.has_another)
                if (reader.peek.type is TokenType.eol) defined_tokens.add( reader.peek ); escapeWhile
                defined_tokens.add( reader.read )
              endWhile
              define( defined_word, defined_tokens )
            else
              # Skip this directive due to conditional compilation - discard tokens to EOL
              while (reader.has_another)
                if (reader.peek.type is TokenType.eol) escapeWhile
                reader.read
              endWhile
            endIf
            nextIteration

          elseIf (t.type is TokenType.directive_defined)
            local defined_word = t->String
            if (keep_tokens)
              if (definitions.contains(defined_word))
                tokens.add( Token(TokenType.keyword_true).set_location(t) )
              else
                tokens.add( Token(TokenType.keyword_false).set_location(t) )
              endIf
            endIf
            nextIteration

          elseIf (t.type is TokenType.directive_error)
            local message_t = reader.read
            if (message_t.type is not TokenType.literal_string)
              throw t.error( "Literal string error message expected." )
            endIf
            if (keep_tokens)
              throw message_t.error( message_t->String )
            endIf
            nextIteration

          elseIf (t.type is TokenType.directive_include)
            local filepath_t = reader.read
            if (filepath_t.type is not TokenType.literal_string)
              throw reader.error( "Filepath expected." )
            endIf
            local is_optional = consume_optional
            if (keep_tokens)
              RogueC.include_source( t, filepath_t->String, &is_optional=is_optional )
            # else next literal string will be discarded anyway
            endIf
            nextIteration

          elseIf (t.type is TokenType.directive_elseIf)
            if (depth == 1) throw t.error( "Syntax error - $elseIf does not match any previous $if." )
            reader.push( t )
            return

          elseIf (t.type is TokenType.directive_else)
            if (depth == 1) throw t.error( "Syntax error - $else does not match any previous $if." )
            reader.push( t )
            return

          elseIf (t.type is TokenType.directive_endIf)
            if (depth == 1) throw t.error( "Syntax error - $endIf does not match any previous $if." )
            reader.push( t )
            return

          elseIf (t.type is TokenType.directive_if)
            local found_true = parse_logical_expression
            local single_line = not reader.next_is( TokenType.eol )

            if (found_true)
              process( keep_tokens, depth, single_line )
            else
              process( false, depth, single_line )
            endIf

            while (reader.peek.type is TokenType.directive_elseIf)
              reader.read
              local value = parse_logical_expression

              if (found_true)
                process( false, depth, single_line )
              else
                found_true = value
                if (value) process( keep_tokens, depth, single_line )
                else       process( false, depth, single_line )
              endIf
            endWhile

            if (reader.peek.type is TokenType.directive_else)
              reader.read
              if (found_true) process( false,       depth, single_line )
              else            process( keep_tokens, depth, single_line )
            endIf

            if (not single_line) must_consume( TokenType.directive_endIf )
            nextIteration

          elseIf (t.type is TokenType.directive_warning)
            local message_t = reader.read
            if (message_t.type is not TokenType.literal_string)
              throw t.error( "Literal string warning message expected." )
            endIf
            if (keep_tokens)
              Console.error.println message_t.warning( message_t->String )
            endIf
            nextIteration

          elseIf (t.type is TokenType.directive_module)
            if (keep_tokens) tokens.add( t )

            if (next_is(TokenType.identifier))
              if (keep_tokens) tokens.add( reader.peek )
              cur_module = reader.read_identifier
            else
              cur_module = null
            endIf

            if (next_is(TokenType.symbol_open_bracket))
              # [essential]
              if (keep_tokens)
                tokens.add( reader.read )
                while (reader.has_another)
                  tokens.add( reader.read )
                  if (tokens.last.type is TokenType.symbol_close_bracket) escapeWhile
                endWhile
              else
                reader.read
                while (reader.has_another)
                  local next_token = reader.read
                  if (next_token.type is TokenType.symbol_close_bracket) escapeWhile
                endWhile
              endIf
            endIf

            nextIteration

          elseIf (t.type is TokenType.meta_moduleName)
            if (keep_tokens)
              if (cur_module) tokens.add( TokenType.literal_string.create_token(t,cur_module) )
              else            tokens.add( TokenType.literal_string.create_token(t,"") )
              repeat_string_concatenation = true
            endIf
            nextIteration
          endIf
        endIf

        if (t.type is TokenType.keyword_class or t.type is TokenType.keyword_routine or t.type is TokenType.keyword_enum)
          if (cur_module and reader.peek.type is TokenType.identifier)
            if (keep_tokens) tokens.add( t )
            t = reader.read
            local class_name = t->String
            Program.add_module_id( cur_module, class_name )
            if (keep_tokens)
              tokens.add( t.type.create_token(t,"$::$"(cur_module,class_name)) )
            endIf
            nextIteration
          endIf
        endIf

        if (t.type is TokenType.literal_string)
          while (reader.peek.type is TokenType.literal_string)
            t = t.type.create_token( t, t->String + reader.read->String )
          endWhile
        endIf

        if (keep_tokens) tokens.add( t )
        if (stop_on_eol and t.type is TokenType.eol) escapeWhile

      endWhile

      if (repeat_string_concatenation)
        forEach (t in rewriter=tokens.rewriter)
          if (t.type is TokenType.literal_string)
            while (rewriter.has_another and rewriter.peek.type is TokenType.literal_string)
              t = t.type.create_token( t, t->String + rewriter.read->String )
            endWhile
          endIf
          rewriter.write( t )
        endForEach
      endIf

    method consume_optional->Logical
      if (not consume(TokenType.symbol_open_bracket)) return false
      local is_optional = false
      while (consume("optional")) is_optional = true
      if (not next_is(TokenType.symbol_close_bracket))
        throw reader.peek.error( "Keyword 'optional' or closing ']' expected." )
      endIf
      must_consume( TokenType.symbol_close_bracket )
      return is_optional

    method must_consume( type:TokenType )
      local message = "Expected '$'." (type.name)
      if (not reader.has_another) throw RogueError( message )
      local t = reader.read
      if (t.type is not type) throw t.error( message )

    method next_is( type:TokenType )->Logical
      return reader.next_is( type )

    method parse_logical_expression->Logical
      return parse_logical_or

    method parse_logical_or->Logical
      return parse_logical_or( parse_logical_and )

    method parse_logical_or( lhs:Logical )->Logical
      if (consume(TokenType.keyword_or)) return parse_logical_or( parse_logical_and or lhs )
      return lhs

    method parse_logical_and->Logical
      return parse_logical_and( parse_logical_term )

    method parse_logical_and( lhs:Logical )->Logical
      if (consume(TokenType.keyword_and)) return parse_logical_and( parse_logical_term and lhs )
      return lhs

    method parse_logical_term->Logical
      loop
        local t = reader.peek
        if (consume(TokenType.keyword_not))
          local result = (not parse_logical_term)
          return result
        endIf

        if (consume(TokenType.symbol_open_paren))
          local result = parse_logical_expression
          must_consume(TokenType.symbol_close_paren)
          return result
        endIf

        if (t.type is TokenType.literal_string)
          local target = reader.read->String
          local result = RogueC.compile_targets[target]->Logical
          return result
        endIf

        if (t.type is TokenType.symbol_minus)
          reader.read
          t = reader.peek
          if (not (t.type is TokenType.literal_int32 or t.type is TokenType.literal_int64))
            throw t.error( "Syntax error: unexpected '-'." )
          endIf
          return (reader.read->Int32)?
        endIf

        if (t.type is TokenType.literal_int32 or t.type is TokenType.literal_int64)
          return (reader.read->Int32)?
        endIf

        if (consume(TokenType.directive_defined))
          return (definitions.contains(t->String))
        endIf

        if (consume(TokenType.identifier))
          # If the parser finds an identifier here it means it's undefined.
          return false
        endIf

        if (consume(TokenType.keyword_true))  return true
        if (consume(TokenType.keyword_false)) return false
        throw reader.peek.error( "Syntax error in directive: '$'." (reader.peek) )
      endLoop

    method read_identifier->String
      local t = reader.peek
      if (t.type is not TokenType.identifier) throw t.error( "Identifier expected instead of '$'." (t) )
      return reader.read->String

    method reprocess( tokens )->Token[]
      # All the heavy lifting has been done.  Just join any string literals that may now be
      # adjacent after a new template instance.
      local rewriter = tokens.rewriter
      while (rewriter.has_another)
        local t = rewriter.read
        while (t.type is TokenType.literal_string and rewriter.has_another and rewriter.peek.type is TokenType.literal_string)
          t = t.type.create_token( t, t->String + rewriter.read->String )
        endWhile
        rewriter.write( t )
      endWhile

      return tokens
endClass

