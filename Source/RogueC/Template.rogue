class Template
  PROPERTIES
    t                  : Token
    name               : String
    tokens=Token[]     : Token[]
    attributes         = Attributes()
    type_parameters    : TypeParameter[]
    used_modules       = String[]

  METHODS
    method init( t, modules:String[], name, attribute_flags=0:Int32 )
      attributes.add( attribute_flags )
      if (modules)
        forEach (module in modules) used_modules.add( modules )
      endIf

    method add_type_parameter( p_t:Token, p_name:String )->TypeParameter
      if (type_parameters is null) type_parameters = TypeParameter[]
      local param = TypeParameter( p_t, p_name )
      type_parameters.add( param )
      return param

    method element_type->Int32
      return (attributes.flags & Attribute.type_mask)

    method instantiate( type:Type, scope:Scope )
      type.t = t
      # replace location of first reference to type with location of type definition

      # Add used modules in the scope where the type was defined
      forEach (m_name in used_modules) type.add_used_module( m_name )

      type.attributes.add( attributes )

      local augmented_tokens = tokens
      local augments : Augment[]
      local possible_augments = Program.augment_lookup[ type.name ]
      if (possible_augments) augments = Augment[].add( possible_augments )

      possible_augments = Program.augment_lookup[ type.name.after_any(':') ]
      if (possible_augments)
        forEach (aug in possible_augments)
          forEach (path in aug.used_modules)
            if (path + aug.name == type.name)
              if (not augments) augments = Augment[]
              augments.add( aug )
            endIf
          endForEach
        endForEach
      endIf

      if (augments)
        local t_count = tokens.count
        forEach (aug in augments) t_count += aug.tokens.count

        augmented_tokens = Token[]( t_count )
        augmented_tokens.add( tokens )
        augmented_tokens.remove_last  # will be an EOL
        augmented_tokens.add( Token(TokenType.begin_augment_tokens) )
        forEach (aug in augments)
          forEach (base_type in aug.base_types)
            type.base_types.add( base_type )
          endForEach
          augmented_tokens.add( aug.tokens )
        endForEach
        augmented_tokens.add( tokens.last )  # add the EOL back in
      endIf

      if (type.name.ends_with(']'))
        instantiate_list( type, augmented_tokens )
      elseIf (type.name.ends_with('?'))
        instantiate_optional( type, augmented_tokens )
      elseIf (type_parameters)
        instantiate_parameterized_type( type, augmented_tokens )
      else
        instantiate_standard_type( type, augmented_tokens )
      endIf

    method instantiate_list( type:Type, augmented_tokens:Token[] )
      type.is_list = true
      type.element_type = Program.get_type_reference( t, type.name.leftmost(-2) ).organize

      local instance_tokens = Token[]( augmented_tokens.count )
      forEach (template_t in augmented_tokens)
        if (template_t.type is TokenType.placeholder_id)
          if (template_t->String == "$DataType")
            instance_tokens.add( TokenType.identifier.create_token(template_t,type.element_type.name) )
          else
            instance_tokens.add( template_t )
          endIf
        else
          instance_tokens.add( template_t )
        endIf
      endForEach

      Parser(instance_tokens).parse_type_def( type )

    method instantiate_optional( type:Type, augmented_tokens:Token[] )
      type.is_optional = true
      type.element_type = Program.get_type_reference( t, type.name.leftmost(-1) ).organize

      local instance_tokens = Token[]( augmented_tokens.count )
      forEach (template_t in augmented_tokens)
        if (template_t.type is TokenType.placeholder_id)
          if (template_t->String == "$DataType")
            instance_tokens.add( TokenType.identifier.create_token(template_t,type.element_type.name) )
          else
            instance_tokens.add( template_t )
          endIf
        else
          instance_tokens.add( template_t )
        endIf
      endForEach

      Parser(instance_tokens).parse_type_def( type )

    method instantiate_parameterized_type( type:Type, augmented_tokens:Token[] )
      local instance_tokens = augmented_tokens

      local type_specializers = Table<<String,TypeSpecializer>>()

      local specialization_string = type.name.from_first('<')
      if (specialization_string.count == 0)
        throw type.t.error( "Reference to $ is missing required type parameters ($<<...>>)." (type.name,type.name) )
      endIf

      local parser = Parser( t, type.name, type.name.from_first('<') )
      parser.read  # '<<'

      local buffer = StringBuilder()
      local first = true
      while (first or parser.consume(TokenType.symbol_comma))
        first = false
        local specializer_tokens = Token[]
        parser.parse_specializer( buffer.clear, specializer_tokens )

        local index = type_specializers.count
        if (index >= type_parameters.count) throw t.error( "Too many type specializers given." )

        local param = type_parameters[index]
        local specializer = TypeSpecializer( param.name, index )
        specializer.tokens = specializer_tokens
        type_specializers[specializer.name] = specializer

      endWhile

      if (type_specializers.count < type_parameters.count)
        throw type.t.error( "Insufficient number of type parameters in $; $ given, $ expected." (type.name,type_specializers.count,type_parameters.count) ) 
      endIf

      # Create specialized instance tokens
      instance_tokens = Token[]( augmented_tokens.count * 2 )
      forEach (template_t in augmented_tokens)
        if (template_t.type is TokenType.placeholder_id)
          local specializer = type_specializers[ template_t->String ]
          if (specializer)
            # Insert template copy of tokens
            forEach (specializer_t in specializer.tokens)
              instance_tokens.add( specializer_t )
            endForEach
          else
            instance_tokens.add( template_t )
          endIf
        else
          instance_tokens.add( template_t )
        endIf
      endForEach

      Parser(instance_tokens).parse_type_def( type )

    method instantiate_standard_type( type:Type, augmented_tokens:Token[] )
      if (type.name.contains('<'))
        throw t.error( "Type parameters given for non-template type." )
      endIf

      Parser(augmented_tokens).parse_type_def( type )

endClass


class TypeParameter
  PROPERTIES
    t               : Token
    name            : String
 
  METHODS
    method init( t, name )
endClass


class TypeSpecializer
  PROPERTIES
    name            : String
    index           : Int32

    tokens          : Token[]  # for templates

  METHODS
    method init( name, index )
endClass

